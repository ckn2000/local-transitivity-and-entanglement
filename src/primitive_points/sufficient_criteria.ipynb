{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7956a19-236a-4cec-89cb-1e4547bc6561",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utilities.ipynb\n",
    "%run algorithm_1.ipynb\n",
    "%run algorithm_2.ipynb\n",
    "%run reduction_subroutine.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b62f8d-a9f4-415f-aa5e-ff9f561ab8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN EXECUTION\n",
    "\n",
    "import time\n",
    "import gc\n",
    "import json\n",
    "\n",
    "def batch_process_all_files(inpath,outpath):\n",
    "    \"\"\"Process all files in directory with JSONL output format.\"\"\"\n",
    "    result_dir = Path(inpath)\n",
    "    output_dir = Path(outpath)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    txt_files = list(result_dir.glob(\"*.txt\"))\n",
    "    print(f\"Processing {len(txt_files)} files...\")\n",
    "    \n",
    "    for input_file in txt_files:\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        input_path = Path(input_file)\n",
    "        output_filename = f\"{input_path.stem}-criteria-check.jsonl\"\n",
    "        output_path = output_dir / output_filename\n",
    "        \n",
    "        print(f\"Processing: {input_path.name}\")\n",
    "        print(f\"Output will be saved to: {output_path}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        record_count = 0\n",
    "        \n",
    "        # Clear caches periodically to prevent memory bloat\n",
    "        if len(_primitive_vector_cache) > 1000:\n",
    "            _primitive_vector_cache.clear()\n",
    "        if len(_orbit_cache) > 1000:\n",
    "            _orbit_cache.clear()\n",
    "        if len(_stabilizer_cache) > 1000:\n",
    "            _stabilizer_cache.clear()\n",
    "        \n",
    "        # Open output file for writing JSONL\n",
    "        with open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "            \n",
    "            for rec in parse_count_file(input_path):\n",
    "                label = rec[\"label\"]\n",
    "                N = Integer(rec[\"N\"])\n",
    "                m0 = Integer(rec[\"m0\"])\n",
    "                count = rec.get(\"count\", \"N/A\")\n",
    "                adelic_gens = rec[\"adelic_gens\"]\n",
    "                \n",
    "                record_count += 1\n",
    "                record_start = time.time()\n",
    "                \n",
    "                def run_algorithms():\n",
    "                    # Initialize result structure\n",
    "                    result = {\n",
    "                        \"label\": label,\n",
    "                        \"N\": int(N),\n",
    "                        \"m0\": int(m0),\n",
    "                        \"count\": count,\n",
    "                        \"main_status\": \"FAIL\",\n",
    "                        \"fail_stage\": \"NONE\",\n",
    "                        \"ef_status\": \"SKIPPED_INPUT\",\n",
    "                        \"lt_first_fail\": None,\n",
    "                        \"lt_components_passed\": 1,\n",
    "                        \"lt_data\": {},\n",
    "                        \"ef_first_fail_pair\": None,\n",
    "                        \"ef_first_fail_side\": None,\n",
    "                        \"ef_first_fail_orbit_rep\": None,\n",
    "                        \"ef_first_fail_stab_generated_index\": None,\n",
    "                        \"ef_first_fail_Gamma_index\": None,\n",
    "                        \"ef_first_fail_NA_index\": None,\n",
    "                        \"ef_first_fail_NB_index\": None,\n",
    "                        \"ef_pairs_checked\": 0,\n",
    "                        \"ef_max_Gamma_index\": None,\n",
    "                        \"ef_max_stab_generated_index\": None\n",
    "                    }\n",
    "                    \n",
    "                    try:\n",
    "                        # Algorithm 1: Check transitivity for each prime power divisor of m0 using _algorithm1\n",
    "                        algo1pass = True\n",
    "                        lt_components_passed = 1\n",
    "                        \n",
    "                        # Sort prime powers by size to check smaller ones first\n",
    "                        prime_powers = [(Integer(l), Integer(k)) for (l, k) in factor(m0)]\n",
    "                        prime_powers.sort(key=lambda x: x[0]**x[1])\n",
    "                        \n",
    "                        for l, k in prime_powers:\n",
    "                            n = l**k\n",
    "                            gens_lk = reduction_mod_n(adelic_gens, N, n)\n",
    "                            \n",
    "                            # Use _algorithm1 with data collection to check transitivity\n",
    "                            algo1_data = _algorithm1(gens_lk, l, k, collect_data=True)\n",
    "                            algo1_result = algo1_data[\"result\"]\n",
    "                            \n",
    "                            result[\"lt_data\"][f\"[{int(l)},{int(k)}]\"] = {\n",
    "                                \"status\": algo1_data[\"status\"],\n",
    "                                \"orbit_size\": algo1_data[\"orbit_size\"],\n",
    "                                \"target_size\": algo1_data[\"target_size\"],\n",
    "                                \"deficit\": algo1_data[\"deficit\"]\n",
    "                            }\n",
    "                            \n",
    "                            if not algo1_result:\n",
    "                                algo1pass = False\n",
    "                                if result[\"lt_first_fail\"] is None:\n",
    "                                    result[\"lt_first_fail\"] = [int(l), int(k)]\n",
    "                                break\n",
    "                            else:\n",
    "                                lt_components_passed *= n\n",
    "                        \n",
    "                        result[\"lt_components_passed\"] = int(lt_components_passed)\n",
    "                        \n",
    "                        if not algo1pass:\n",
    "                            result[\"main_status\"] = \"FAIL\"\n",
    "                            result[\"fail_stage\"] = \"LT\"\n",
    "                            result[\"ef_status\"] = \"SKIPPED_LT_FAIL\"\n",
    "                            return result\n",
    "                        \n",
    "                        # Algorithm 2: Check EF_{m0} condition only if Algorithm 1 passes\n",
    "                        gens_m0 = reduction_mod_n(adelic_gens, N, m0)\n",
    "                        algo2pass = _algorithm2(gens_m0, m0)\n",
    "                        \n",
    "                        if algo2pass:\n",
    "                            result[\"main_status\"] = \"PASS\"\n",
    "                            result[\"fail_stage\"] = \"NONE\"\n",
    "                            result[\"ef_status\"] = \"PASS\"\n",
    "                        else:\n",
    "                            result[\"main_status\"] = \"FAIL\"\n",
    "                            result[\"fail_stage\"] = \"EF\"\n",
    "                            result[\"ef_status\"] = \"FAIL\"\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        result[\"main_status\"] = \"FAIL\"\n",
    "                        result[\"fail_stage\"] = \"ERROR\"\n",
    "                        result[\"ef_status\"] = \"SKIPPED_INPUT\"\n",
    "                    \n",
    "                    result[\"record_time\"] = float(time.time() - record_start)\n",
    "                    return result\n",
    "                \n",
    "                # Run algorithms without timeout limit\n",
    "                try:\n",
    "                    algorithm_result = run_algorithms()\n",
    "                    exception = None\n",
    "                except Exception as e:\n",
    "                    algorithm_result = None\n",
    "                    exception = e\n",
    "                \n",
    "                if exception is not None:\n",
    "                    # Handle exception\n",
    "                    result_data = {\n",
    "                        \"label\": label, \"N\": int(N), \"m0\": int(m0), \"count\": count,\n",
    "                        \"main_status\": \"FAIL\", \"fail_stage\": \"ERROR\", \n",
    "                        \"ef_status\": \"SKIPPED_ERROR\", \"lt_first_fail\": None,\n",
    "                        \"lt_components_passed\": 1, \"lt_data\": {},\n",
    "                        \"ef_first_fail_pair\": None, \"ef_first_fail_side\": None,\n",
    "                        \"ef_first_fail_orbit_rep\": None,\n",
    "                        \"ef_first_fail_stab_generated_index\": None,\n",
    "                        \"ef_first_fail_Gamma_index\": None, \"ef_first_fail_NA_index\": None,\n",
    "                        \"ef_first_fail_NB_index\": None, \"ef_pairs_checked\": 0,\n",
    "                        \"ef_max_Gamma_index\": None, \"ef_max_stab_generated_index\": None,\n",
    "                        \"record_time\": float(time.time() - record_start)\n",
    "                    }\n",
    "                else:\n",
    "                    result_data = algorithm_result\n",
    "                \n",
    "                # More robust Sage type conversion\n",
    "                def convert_sage_types(obj):\n",
    "                    # Handle None\n",
    "                    if obj is None:\n",
    "                        return None\n",
    "                    # Handle dictionaries\n",
    "                    elif isinstance(obj, dict):\n",
    "                        return {str(k): convert_sage_types(v) for k, v in obj.items()}\n",
    "                    # Handle lists and tuples\n",
    "                    elif isinstance(obj, (list, tuple)):\n",
    "                        return [convert_sage_types(item) for item in obj]\n",
    "                    # Handle Sage integers and numbers\n",
    "                    elif hasattr(obj, 'lift') or hasattr(obj, '_integer_') or str(type(obj)).startswith('sage.'):\n",
    "                        try:\n",
    "                            return int(obj)\n",
    "                        except:\n",
    "                            try:\n",
    "                                return float(obj)\n",
    "                            except:\n",
    "                                return str(obj)\n",
    "                    # Handle Sage floats\n",
    "                    elif hasattr(obj, '_float_'):\n",
    "                        return float(obj)\n",
    "                    # Handle other numeric types\n",
    "                    elif isinstance(obj, (int, float, str, bool)):\n",
    "                        return obj\n",
    "                    # Handle anything else by converting to string\n",
    "                    else:\n",
    "                        return str(obj)\n",
    "                \n",
    "                result_data = convert_sage_types(result_data)\n",
    "                \n",
    "                # Write as JSON line (JSONL format)\n",
    "                outfile.write(json.dumps(result_data) + '\\n')\n",
    "                \n",
    "                # Print progress (fixed to use Python int)\n",
    "                if record_count % 10 == 0:\n",
    "                    print(f\"  Processed {record_count} records...\")\n",
    "                \n",
    "                # Garbage collection periodically\n",
    "                if record_count % 50 == 0:\n",
    "                    gc.collect()\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        # Write summary to separate file\n",
    "        summary_path = output_path.with_suffix('.summary.txt')\n",
    "        with open(summary_path, 'w', encoding='utf-8') as summary_file:\n",
    "            summary_file.write(f\"Processing summary for {input_path.name}\\n\")\n",
    "            summary_file.write(f\"Total time: {total_time:.2f}s\\n\")\n",
    "            summary_file.write(f\"Records processed: {record_count}\\n\")\n",
    "            summary_file.write(f\"Average time per record: {total_time/record_count:.3f}s\\n\")\n",
    "            summary_file.write(f\"Output saved to: {output_path}\\n\")\n",
    "            summary_file.write(f\"Note: No timeout limit - entries run as long as needed\\n\")\n",
    "        \n",
    "        print(f\"  === SUMMARY ===\")\n",
    "        print(f\"  Records processed: {record_count}\")\n",
    "        print(f\"  Total time: {total_time:.2f}s\")\n",
    "        print(f\"  Average time per record: {total_time/record_count:.3f}s\")\n",
    "        print(f\"  Results saved to: {output_path}\")\n",
    "        print(f\"  Summary saved to: {summary_path}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adda18c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run batch processing\n",
    "inpath = input(\"In-path: \") #should be ../result/point_count\n",
    "outpath = input(\"Out-path: \") #should be ../result/criteria_check\n",
    "batch_process_all_files(inpath, outpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 10.8",
   "language": "sage",
   "name": "SageMath-10.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
